{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8316c4",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f2866f",
   "metadata": {},
   "source": [
    "Download the data set from this experiment (resume_experiment.dta) from github. To aid the autograder, please load the data directly from a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb6d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_format = \"test if black is working\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac079af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "\n",
    "url = \"https://github.com/nickeubank/MIDS_Data/raw/refs/heads/master/resume_experiment/resume_experiment.dta\"\n",
    "df = pd.read_stata(url)\n",
    "#  df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19a80d",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4af274",
   "metadata": {},
   "source": [
    "- black is the treatment variable in the data set (whether the resume has a “Black-sounding” name).\n",
    "\n",
    "- call is the dependent variable of interest (did the employer call the fictitious applicant for an interview)\n",
    "\n",
    "In addition, the data include a number of variables to describe the other features in each fictitious resume, including applicants education level (education), years of experience (yearsexp), gender (female), computer skills (computerskills), and number of previous jobs (ofjobs). Each resume has a random selection of these attributes, so on average the Black-named fictitious applicant resumes have the same qualifications as the White-named applicant resumes.\n",
    "\n",
    "Check for balance in terms of the average values of applicant gender (female), computer skills (computerskills), and years of experience (yearsexp) across the two arms of the experiment (i.e. by black). Calculate both the differences in means across treatment arms and test for statistical significance of these differences. Does gender, computer skills, and yearsexp look balanced across race groups in terms of both statistical significance and magnitude of difference?\n",
    "\n",
    "Store the p-values associated with your t-test of these variables in ex2_pvalue_female, ex2_pvalue_computerskills, and ex2_pvalue_yearsexp. Round your values to 2 decimal places.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "928fb6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance Check Across Treatment Arms (black)\n",
      "================================================================================\n",
      "      Variable  Mean (black=0)  Mean (black=1)  Difference  t-statistic  p-value Significant (α=0.05)\n",
      "        female        0.763860        0.774538    0.010678    -0.884132 0.376669                   No\n",
      "computerskills        0.808624        0.832444    0.023819    -2.166427 0.030327                  Yes\n",
      "      yearsexp        7.856263        7.829569   -0.026694     0.184620 0.853535                   No\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Interpretation:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "female:\n",
      "  Difference: 0.0107\n",
      "  Statistical significance: No (p=0.3767)\n",
      "  Magnitude: very small\n",
      "\n",
      "computerskills:\n",
      "  Difference: 0.0238\n",
      "  Statistical significance: Yes (p=0.0303)\n",
      "  Magnitude: very small\n",
      "\n",
      "yearsexp:\n",
      "  Difference: -0.0267\n",
      "  Statistical significance: No (p=0.8535)\n",
      "  Magnitude: very small\n"
     ]
    }
   ],
   "source": [
    "# Group by treatment variable (black)\n",
    "balance_check = pd.DataFrame()\n",
    "variables = [\"female\", \"computerskills\", \"yearsexp\"]\n",
    "results = []\n",
    "\n",
    "for var in variables:\n",
    "    # Calculate means for each group\n",
    "    mean_black_0 = df[df[\"black\"] == 0][var].mean()\n",
    "    mean_black_1 = df[df[\"black\"] == 1][var].mean()\n",
    "\n",
    "    # Calculate difference\n",
    "    difference = mean_black_1 - mean_black_0\n",
    "\n",
    "    # Perform t-test\n",
    "    group_0 = df[df[\"black\"] == 0][var]\n",
    "    group_1 = df[df[\"black\"] == 1][var]\n",
    "    t_stat, p_value = stats.ttest_ind(group_0, group_1)\n",
    "\n",
    "    # Store results\n",
    "    results.append(\n",
    "        {\n",
    "            \"Variable\": var,\n",
    "            \"Mean (black=0)\": mean_black_0,\n",
    "            \"Mean (black=1)\": mean_black_1,\n",
    "            \"Difference\": difference,\n",
    "            \"t-statistic\": t_stat,\n",
    "            \"p-value\": p_value,\n",
    "            \"Significant (α=0.05)\": \"Yes\" if p_value < 0.05 else \"No\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "balance_table = pd.DataFrame(results)\n",
    "print(\"Balance Check Across Treatment Arms (black)\")\n",
    "print(\"=\" * 80)\n",
    "print(balance_table.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Summary interpretation\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"-\" * 80)\n",
    "for _, row in balance_table.iterrows():\n",
    "    print(f\"\\n{row['Variable']}:\")\n",
    "    print(f\"  Difference: {row['Difference']:.4f}\")\n",
    "    print(\n",
    "        f\"  Statistical significance: {row['Significant (α=0.05)']} (p={row['p-value']:.4f})\"\n",
    "    )\n",
    "\n",
    "    # Magnitude assessment\n",
    "    if abs(row[\"Difference\"]) < 0.1:\n",
    "        magnitude = \"very small\"\n",
    "    elif abs(row[\"Difference\"]) < 0.5:\n",
    "        magnitude = \"small\"\n",
    "    elif abs(row[\"Difference\"]) < 1.0:\n",
    "        magnitude = \"moderate\"\n",
    "    else:\n",
    "        magnitude = \"large\"\n",
    "    print(f\"  Magnitude: {magnitude}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243a1d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex2_pvalue_female = 0.38\n",
      "ex2_pvalue_computerskills = 0.03\n",
      "ex2_pvalue_yearsexp = 0.85\n"
     ]
    }
   ],
   "source": [
    "# Calculate p-values for each variable\n",
    "# T-test comparing black=0 vs black=1 groups\n",
    "\n",
    "# For female\n",
    "group_0_female = df[df[\"black\"] == 0][\"female\"]\n",
    "group_1_female = df[df[\"black\"] == 1][\"female\"]\n",
    "t_stat, p_value = stats.ttest_ind(group_0_female, group_1_female)\n",
    "ex2_pvalue_female = round(p_value, 2)\n",
    "\n",
    "# For computerskills\n",
    "group_0_computerskills = df[df[\"black\"] == 0][\"computerskills\"]\n",
    "group_1_computerskills = df[df[\"black\"] == 1][\"computerskills\"]\n",
    "t_stat, p_value = stats.ttest_ind(group_0_computerskills, group_1_computerskills)\n",
    "ex2_pvalue_computerskills = round(p_value, 2)\n",
    "\n",
    "# For yearsexp\n",
    "group_0_yearsexp = df[df[\"black\"] == 0][\"yearsexp\"]\n",
    "group_1_yearsexp = df[df[\"black\"] == 1][\"yearsexp\"]\n",
    "t_stat, p_value = stats.ttest_ind(group_0_yearsexp, group_1_yearsexp)\n",
    "ex2_pvalue_yearsexp = round(p_value, 2)\n",
    "\n",
    "# Display results\n",
    "print(f\"ex2_pvalue_female = {ex2_pvalue_female}\")\n",
    "print(f\"ex2_pvalue_computerskills = {ex2_pvalue_computerskills}\")\n",
    "print(f\"ex2_pvalue_yearsexp = {ex2_pvalue_yearsexp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ecd05d",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d2ad3c",
   "metadata": {},
   "source": [
    "Do a similar tabulation for education (education). Education is a categorical variable coded as follows:\n",
    "\n",
    "    0: Education not reported\n",
    "\n",
    "    1: High school dropout\n",
    "\n",
    "    2: High school graduate\n",
    "\n",
    "    3: Some college\n",
    "\n",
    "    4: College graduate or higher\n",
    "\n",
    "Because these are categorical, you shouldn’t just calculate and compare means—you should compare share or count of observations with each value (e.g., a chi-squared contingency table). You may also find the pd.crosstab function useful.\n",
    "\n",
    "Does education look balanced across racial groups?\n",
    "\n",
    "Store the p-value from your chi squared test in results under the key ex3_pvalue_education. Please round to 2 decimal places.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9cbf75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table: Education by Black\n",
      "==================================================\n",
      "black       0.0   1.0\n",
      "education            \n",
      "0            18    28\n",
      "1            18    22\n",
      "2           142   132\n",
      "3           513   493\n",
      "4          1744  1760\n",
      "\n",
      "\n",
      "Chi-Squared Test Results:\n",
      "==================================================\n",
      "Chi-squared statistic: 3.4096\n",
      "Degrees of freedom: 4\n",
      "P-value: 0.4918\n",
      "Significant at α=0.05: No\n",
      "\n",
      "ex3_pvalue_education = 0.49\n"
     ]
    }
   ],
   "source": [
    "# Create a contingency table (crosstab) for education by black\n",
    "contingency_table = pd.crosstab(df[\"education\"], df[\"black\"])\n",
    "\n",
    "print(\"Contingency Table: Education by Black\")\n",
    "print(\"=\" * 50)\n",
    "print(contingency_table)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Perform chi-squared test\n",
    "chi2_stat, p_value, dof, expected_freq = chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"Chi-Squared Test Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Chi-squared statistic: {chi2_stat:.4f}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Significant at α=0.05: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# Store the p-value rounded to 2 decimal places\n",
    "ex3_pvalue_education = round(p_value, 2)\n",
    "\n",
    "print(f\"\\nex3_pvalue_education = {ex3_pvalue_education}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e195c1f",
   "metadata": {},
   "source": [
    "> Education appears BALANCED across racial groups p > 0.05\n",
    "> The distribution of education levels is not significantly different between black=0 and black=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e13a84",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a401cde",
   "metadata": {},
   "source": [
    "What do you make of the overall results on resume characteristics? Why do we care about whether these variables look similar across the race groups? And if they didn’t look similar, would that be a threat to internal or external validity?\n",
    "\n",
    "Answer in markdown, then also store your answer to the question of whether imbalances are a threat to internal or external validity in \"ex4_validity\" as the string \"internal\" or \"external\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869fef85",
   "metadata": {},
   "source": [
    "> To summarize the statistics, all variables across gender, education level, computer skills, years of experience are balanced across both black and non-black groups.\n",
    "\n",
    "> This is highly important, since differences between these variables mean we wouldn't be able to 100% say that differences in callbacks are 100% due to the differences in perceived name, and instead these other factors which affect job callback rates e.g. we expect higher education/more YOE to get more callbacks.\n",
    "\n",
    "> This affects the internal validity of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0043d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex4_validity = \"internal\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96de806",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7a68e",
   "metadata": {},
   "source": [
    "The variable of interest in the data set is the variable call, which indicates a call back for an interview. Perform a two-sample t-test comparing applicants with black sounding names and white sounding names.\n",
    "\n",
    "Interpret your results—in both percentage and in percentage points, what is the effect of having a Black-sounding name (as opposed to a White-sounding name) on your resume?\n",
    "\n",
    "Store how much more likely a White applicant is to receive a call back than a Black respondent in percentage and percentage points in \"ex5_white_advantage_percent\"and \"ex5_white_advantage_percentage_points\". Please scale percentages so 1 is 1% and percentage points so a value of 1 corresponds to 1 percentage point. Please round these answers to 2 decimal places.\n",
    "\n",
    "Store the p-value of the difference in \"ex5_pvalue\" Please round your p-value to 5 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f10ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black applicant callback rate: 0.0645 (6.45%)\n",
      "White applicant callback rate: 0.0965 (9.65%)\n",
      "\n",
      "T-statistic: 4.1147\n",
      "P-value: 0.00004\n",
      "\n",
      "White advantage:\n",
      "  Percentage points: 3.20 percentage points\n",
      "  Percent: 49.68%\n",
      "\n",
      "Stored results:\n",
      "3.2\n",
      "49.68\n",
      "4e-05\n"
     ]
    }
   ],
   "source": [
    "# Calculate callback rates for each group\n",
    "black_callbacks = df[df[\"black\"] == 1][\"call\"]\n",
    "white_callbacks = df[df[\"black\"] == 0][\"call\"]\n",
    "\n",
    "# Calculate means\n",
    "black_rate = black_callbacks.mean()\n",
    "white_rate = white_callbacks.mean()\n",
    "\n",
    "print(f\"Black applicant callback rate: {black_rate:.4f} ({black_rate*100:.2f}%)\")\n",
    "print(f\"White applicant callback rate: {white_rate:.4f} ({white_rate*100:.2f}%)\")\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(white_callbacks, black_callbacks)\n",
    "\n",
    "print(f\"\\nT-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.5f}\")\n",
    "\n",
    "# Calculate the advantage for white applicants\n",
    "# Percentage points difference (absolute difference in rates)\n",
    "percentage_points_diff = (white_rate - black_rate) * 100\n",
    "\n",
    "# Percent difference (relative difference)\n",
    "percent_diff = ((white_rate - black_rate) / black_rate) * 100\n",
    "\n",
    "print(f\"\\nWhite advantage:\")\n",
    "print(f\"  Percentage points: {percentage_points_diff:.2f} percentage points\")\n",
    "print(f\"  Percent: {percent_diff:.2f}%\")\n",
    "\n",
    "# Results\n",
    "ex5_white_advantage_percentage_points = round(percentage_points_diff, 2)\n",
    "ex5_white_advantage_percent = round(percent_diff, 2)\n",
    "ex5_pvalue = round(p_value, 5)\n",
    "\n",
    "print(f\"\\nStored results:\")\n",
    "print(ex5_white_advantage_percentage_points)\n",
    "print(ex5_white_advantage_percent)\n",
    "print(ex5_pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3066835f",
   "metadata": {},
   "source": [
    "> The two-sample t-test reveals statistically significant racial discrimination in callback rates (p = 0.00004). \n",
    "\n",
    "> White applicants received callbacks 9.65% of the time compared to 6.45% for Black applicants, a difference of 3.20 percentage points. This means white applicants are approximately 50% more likely to receive callbacks than Black applicants with identical qualifications. \n",
    "\n",
    "> In practical terms, a Black applicant needs to send roughly 15 resumes to get one callback, while a white applicant needs only 10. The extremely low p-value indicates this disparity reflects systematic discrimination rather than chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aca42d",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e7e4e",
   "metadata": {},
   "source": [
    "Now, use a linear probability model (a linear regression with a 0/1 dependent variable!) to estimate the differential likelihood of being called back by applicant race (i.e. the racial discrimination by employers). Please use statsmodels.\n",
    "\n",
    "Since we have a limited dependent variable, be sure to use heteroskedastic robust standard errors. Personally, I prefer the HC3 implementation, as it tends to do better with smaller samples than other implementations.\n",
    "\n",
    "Interpret these results—what is the effect of having a Black-sounding name (as opposed to a White-sounding name) on your resume in terms of the likelihood you’ll be called back?\n",
    "\n",
    "How does this compare to the estimate you got above in exercise 5?\n",
    "\n",
    "Store the p-value associated with black in \"ex6_black_pvalue\". Please round your pvalue to 5 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca0f516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   call   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                  0.003\n",
      "Method:                 Least Squares   F-statistic:                     16.92\n",
      "Date:                Mon, 26 Jan 2026   Prob (F-statistic):           3.96e-05\n",
      "Time:                        19:10:24   Log-Likelihood:                -562.24\n",
      "No. Observations:                4870   AIC:                             1128.\n",
      "Df Residuals:                    4868   BIC:                             1141.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0965      0.006     16.121      0.000       0.085       0.108\n",
      "black         -0.0320      0.008     -4.114      0.000      -0.047      -0.017\n",
      "==============================================================================\n",
      "Omnibus:                     2969.205   Durbin-Watson:                   1.440\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18927.068\n",
      "Skew:                           3.068   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.458   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
      "  ex6_black_pvalue: 4e-05\n"
     ]
    }
   ],
   "source": [
    "# Linear probability model: regress call on black\n",
    "X = sm.add_constant(df[\"black\"])\n",
    "y = df[\"call\"]\n",
    "\n",
    "# Fit OLS with HC3 robust standard errors\n",
    "model = sm.OLS(y, X)\n",
    "results_lpm = model.fit(cov_type=\"HC3\")\n",
    "\n",
    "# Display results\n",
    "print(results_lpm.summary())\n",
    "\n",
    "# Extract the coefficient and p-value for black\n",
    "black_coef = results_lpm.params[\"black\"]\n",
    "black_pvalue = results_lpm.pvalues[\"black\"]\n",
    "\n",
    "# Store the p-value\n",
    "ex6_black_pvalue = round(black_pvalue, 5)\n",
    "print(f\"  ex6_black_pvalue: {ex6_black_pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c5832b",
   "metadata": {},
   "source": [
    "> The linear probability model confirms the t-test results with identical estimates. The coefficient on black is -0.0320, indicating that having a Black-sounding name reduces callback probability by 3.20 percentage points compared to a white-sounding name (p < 0.001). \n",
    "\n",
    "> The constant of 0.0965 represents the baseline callback rate for white applicants (9.65%), and adding the black coefficient gives 6.45% for Black applicants.\n",
    "\n",
    "> This estimate is identical to Exercise 5 because both methods calculate the same quantity: the difference in mean callback rates between groups. The t-test directly compares group means, while the linear probability model estimates this difference as a regression coefficient. \n",
    "\n",
    ">The advantage of the LPM is that it provides HC3 robust standard errors to account for heteroskedasticity inherent in binary outcomes, though in this case both approaches yield the same highly significant result (p < 0.001)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a73ae3",
   "metadata": {},
   "source": [
    "# Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd94461",
   "metadata": {},
   "source": [
    "Even when doing a randomized experiment, adding control variables to your regression can improve the statistical efficiency of your estimates of the treatment effect (the upside is the potential to explain residual variation; the downside is more parameters to be estimated). Adding controls can be particularly useful when randomization left some imbalances in covariates (which you may have seen above).\n",
    "\n",
    "Now let’s see if we can improve our estimates by adding in other variables as controls. Add in education, yearsexp, female, and computerskills—be sure to treat education as a categorical variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e22c3757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   call   R-squared:                       0.008\n",
      "Model:                            OLS   Adj. R-squared:                  0.006\n",
      "Method:                 Least Squares   F-statistic:                     4.350\n",
      "Date:                Mon, 26 Jan 2026   Prob (F-statistic):           3.04e-05\n",
      "Time:                        19:10:24   Log-Likelihood:                -551.02\n",
      "No. Observations:                4870   AIC:                             1120.\n",
      "Df Residuals:                    4861   BIC:                             1178.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.0821      0.040      2.053      0.040       0.004       0.160\n",
      "black             -0.0316      0.008     -4.076      0.000      -0.047      -0.016\n",
      "yearsexp           0.0032      0.001      3.665      0.000       0.001       0.005\n",
      "female             0.0112      0.010      1.165      0.244      -0.008       0.030\n",
      "computerskills    -0.0186      0.011     -1.616      0.106      -0.041       0.004\n",
      "education_1       -0.0017      0.057     -0.030      0.976      -0.113       0.110\n",
      "education_2    -8.953e-05      0.042     -0.002      0.998      -0.082       0.082\n",
      "education_3       -0.0025      0.039     -0.065      0.948      -0.079       0.074\n",
      "education_4       -0.0047      0.038     -0.124      0.901      -0.080       0.070\n",
      "==============================================================================\n",
      "Omnibus:                     2950.646   Durbin-Watson:                   1.448\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18631.250\n",
      "Skew:                           3.047   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.395   Cond. No.                         225.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n"
     ]
    }
   ],
   "source": [
    "# 2. Convert education to dummies - explicitly set dtype to int\n",
    "education_dummies = pd.get_dummies(\n",
    "    df[\"education\"], prefix=\"education\", drop_first=True, dtype=int\n",
    ")\n",
    "\n",
    "# 3. Combine all variables\n",
    "X_controls = pd.concat(\n",
    "    [df[[\"black\", \"yearsexp\", \"female\", \"computerskills\"]], education_dummies], axis=1\n",
    ")\n",
    "\n",
    "# 4. Final Type Safety: Ensure everything in X and y is numeric (float)\n",
    "X_controls = X_controls.astype(float)\n",
    "y = df[\"call\"].astype(float)\n",
    "\n",
    "# 5. Add constant\n",
    "X_controls = sm.add_constant(X_controls)\n",
    "\n",
    "# 6. Fit the model with HC3 robust standard errors\n",
    "model_controls = sm.OLS(y, X_controls)\n",
    "results_controls = model_controls.fit(cov_type=\"HC3\")\n",
    "\n",
    "# 7. Display results\n",
    "print(results_controls.summary())\n",
    "\n",
    "# 8. Extract the coefficient and p-value for black\n",
    "black_coef_controls = results_controls.params[\"black\"]\n",
    "black_pvalue_controls = results_controls.pvalues[\"black\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7743b",
   "metadata": {},
   "source": [
    "> Adding control variables barely changed the estimated racial discrimination effect. The coefficient on black shifted only slightly from -0.0320 to -0.0316, a difference of 0.0004 percentage points. This minimal change confirms that the experimental design worked as intended, random assignment created balanced groups, so controlling for education, experience, gender, and computer skills doesn't meaningfully alter the race effect.\n",
    "\n",
    ">The controls do explain some additional variation in callbacks. Years of experience positively predicts callbacks (coef = 0.0032, p < 0.001), meaning each additional year increases callback probability by 0.32 percentage points. Interestingly, higher computer skills appears to reduce callbacks (coef = -0.0186, p = 0.106), though this effect is not statistically significant. Gender and education levels show no significant effects on callback rates.\n",
    "\n",
    "> The R-squared increased modestly from 0.003 to 0.008, and the standard error on black decreased slightly from 0.008 to 0.008, providing a minor gain in statistical precision. However, the p-value for racial discrimination remains highly significant (0.00005), and the substantive conclusion is unchanged: having a Black-sounding name reduces callback probability by approximately 3.2 percentage points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d735e3e",
   "metadata": {},
   "source": [
    "# Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c04d4",
   "metadata": {},
   "source": [
    "As you may recall from some past readings (such as this one on the migraine medication Aimovig), our focus on estimating Average Treatment Effects runs the risk of papering over variation in how individuals respond. In the case of Aimovig, for example, nearly no patients actually experienced the Average Treatment Effect of the medication; around half of patients experienced no benefit, while the other half experienced a benefit of about twice the average treatment effect.\n",
    "\n",
    "So far in this analysis we’ve been focusing on the average effect of having a Black-sounding name (as compared to a White-sounding name). But we can actually use our regression framework to look for evidence of heterogeneous treatment effects—effects that are different for different types of people in our data. We accomplish this by interacting a variable we think may be related to experiencing a differential treatment effect with our treatment variable. For example, if we think that applicants with Black-sounding names who have a college degree are likely to experience less discrimination, we can interact black with an indicator for having a college degree. If having a college degree reduces discrimination, we could expect the interaction term to be positive.\n",
    "\n",
    "Is there more or less racial discrimination (the absolute magnitude difference in call back rates between Black and White applicants) among applicants who have a college degree? Store your answer as the string \"more discrimination\" or \"less discrimination\" under the key \"ex8_college_heterogeneity\".\n",
    "\n",
    "Please still include education, yearsexp, female, and computerskills as controls.\n",
    "\n",
    "Note: it’s relatively safe to assume that someone hiring employees who sees a resume that does not report education levels will assume the applicant does not have a college degree. So treat “No education reported” as “not having a college degree.”\n",
    "\n",
    "In percentage points, what is the difference in call back rates:\n",
    "\n",
    "    between White applicants without a college degree and Black applicants without a college degree (ex8_black_nocollege).\n",
    "\n",
    "    between White applicants with a college degree and Black applicants with a college degree (ex8_black_college).\n",
    "\n",
    "Use negative values to denote a lower probability for Black applicants to get a call back. Scale so a value of 1 is a one percentage point difference. Please round your answer to 2 percentage points.\n",
    "\n",
    "Focus on the coefficient values, even if the significance is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0bcffc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   call   R-squared:                       0.008\n",
      "Model:                            OLS   Adj. R-squared:                  0.006\n",
      "Method:                 Least Squares   F-statistic:                     3.911\n",
      "Date:                Mon, 26 Jan 2026   Prob (F-statistic):           5.72e-05\n",
      "Time:                        19:10:24   Log-Likelihood:                -550.88\n",
      "No. Observations:                4870   AIC:                             1122.\n",
      "Df Residuals:                    4860   BIC:                             1187.\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const               0.0734      0.040      1.855      0.064      -0.004       0.151\n",
      "black              -0.0172      0.029     -0.594      0.553      -0.074       0.040\n",
      "college             0.0038      0.026      0.148      0.882      -0.046       0.054\n",
      "black_x_college    -0.0155      0.030     -0.514      0.607      -0.075       0.044\n",
      "yearsexp            0.0032      0.001      3.656      0.000       0.001       0.005\n",
      "female              0.0113      0.010      1.167      0.243      -0.008       0.030\n",
      "computerskills     -0.0187      0.011     -1.625      0.104      -0.041       0.004\n",
      "education_1        -0.0009      0.057     -0.016      0.987      -0.112       0.110\n",
      "education_2         0.0017      0.041      0.042      0.967      -0.078       0.081\n",
      "education_3         0.0030      0.014      0.212      0.832      -0.025       0.031\n",
      "education_4         0.0008      0.013      0.059      0.953      -0.025       0.027\n",
      "==============================================================================\n",
      "Omnibus:                     2950.355   Durbin-Watson:                   1.448\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18626.082\n",
      "Skew:                           3.047   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.393   Cond. No.                     3.25e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
      "[2] The smallest eigenvalue is 4.14e-26. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 10, but rank is 9\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "# Create variables and interaction term\n",
    "df[\"college\"] = ((df[\"education\"] == 3) | (df[\"education\"] == 4)).astype(float)\n",
    "df[\"black_x_college\"] = df[\"black\"].astype(float) * df[\"college\"]\n",
    "\n",
    "X_interaction = pd.DataFrame(\n",
    "    {\n",
    "        \"black\": df[\"black\"].astype(float),\n",
    "        \"college\": df[\"college\"].astype(float),\n",
    "        \"black_x_college\": df[\"black_x_college\"].astype(float),\n",
    "        \"yearsexp\": df[\"yearsexp\"].astype(float),\n",
    "        \"female\": df[\"female\"].astype(float),\n",
    "        \"computerskills\": df[\"computerskills\"].astype(float),\n",
    "    }\n",
    ")\n",
    "\n",
    "education_dummies = pd.get_dummies(\n",
    "    df[\"education\"], prefix=\"education\", drop_first=True, dtype=int\n",
    ")\n",
    "X_interaction = pd.concat([X_interaction, education_dummies.astype(float)], axis=1)\n",
    "X_interaction = sm.add_constant(X_interaction)\n",
    "model_interaction = sm.OLS(df[\"call\"].astype(float), X_interaction)\n",
    "results_interaction = model_interaction.fit(cov_type=\"HC3\")\n",
    "\n",
    "print(results_interaction.summary())\n",
    "\n",
    "black_coef = results_interaction.params[\"black\"]\n",
    "college_coef = results_interaction.params[\"college\"]\n",
    "interaction_coef = results_interaction.params[\"black_x_college\"]\n",
    "gap_nocollege = black_coef * 100\n",
    "gap_college = (black_coef + interaction_coef) * 100\n",
    "\n",
    "# Store results\n",
    "ex8_college_heterogeneity = \"more discrimination\"\n",
    "ex8_black_nocollege = round(gap_nocollege, 2)\n",
    "ex8_black_college = round(gap_college, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93312edb",
   "metadata": {},
   "source": [
    "> The interaction analysis reveals that racial discrimination is larger among college-educated applicants. \n",
    "\n",
    "> Black applicants without college degrees face a 1.72 percentage point callback disadvantage, while Black applicants with college degrees face a 3.27 percentage point disadvantage.\n",
    " \n",
    "> The interaction coefficient of -0.0155 indicates having a college degree increases the racial penalty by 1.55 percentage points, though this is not statistically significant (p = 0.607). This suggests discrimination intensifies rather than diminishes at higher education levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02d5b2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.74\n",
      "-3.28\n"
     ]
    }
   ],
   "source": [
    "print(ex8_black_nocollege)\n",
    "print(ex8_black_college)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fab343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No College Gap: -1.74\n",
      "College Gap: -3.28\n",
      "Result: more discrimination\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 1. Create the 'college' dummy (levels 3 and 4)\n",
    "df[\"college\"] = df[\"education\"].isin([3, 4]).astype(float)\n",
    "\n",
    "# 2. Create the Interaction Term\n",
    "df[\"black_x_college\"] = df[\"black\"].astype(float) * df[\"college\"]\n",
    "\n",
    "# 3. Define Features\n",
    "# IMPORTANT: We use 'college' as our education control here to avoid\n",
    "# multicollinearity with the interaction term.\n",
    "X_vars = [\"black\", \"college\", \"black_x_college\", \"yearsexp\", \"female\", \"computerskills\"]\n",
    "X_interaction = sm.add_constant(df[X_vars].astype(float))\n",
    "\n",
    "# 4. Run the Regression\n",
    "model_interaction = sm.OLS(df[\"call\"].astype(float), X_interaction)\n",
    "results_interaction = model_interaction.fit(cov_type=\"HC3\")\n",
    "\n",
    "# 5. Extract Coefficients\n",
    "# black_coef is the effect for college=0\n",
    "# interaction_coef is how that effect changes for college=1\n",
    "black_coef = results_interaction.params[\"black\"]\n",
    "interaction_coef = results_interaction.params[\"black_x_college\"]\n",
    "\n",
    "# 6. Calculate Gaps in Percentage Points\n",
    "# Formula: (Effect) * 100\n",
    "ex8_black_nocollege = round(black_coef * 100, 2)\n",
    "ex8_black_college = round((black_coef + interaction_coef) * 100, 2)\n",
    "\n",
    "# 7. Determine Heterogeneity\n",
    "# \"More\" vs \"Less\" refers to the absolute magnitude of the gap\n",
    "if abs(ex8_black_college) < abs(ex8_black_nocollege):\n",
    "    ex8_college_heterogeneity = \"less discrimination\"\n",
    "else:\n",
    "    ex8_college_heterogeneity = \"more discrimination\"\n",
    "\n",
    "print(f\"No College Gap: {ex8_black_nocollege}\")\n",
    "print(f\"College Gap: {ex8_black_college}\")\n",
    "print(f\"Result: {ex8_college_heterogeneity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002dd7cf",
   "metadata": {},
   "source": [
    "# Exercise 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d86ec",
   "metadata": {},
   "source": [
    "Now let’s compare men and women—is the penalty for having a Black-sounding name greater for Black men or Black women? Store your answer as \"greater discrimination for men\" or \"greater discrimination for women\" in \"ex9_gender_and_discrimination\".\n",
    "\n",
    "Focus on the coefficient values, even if the significance is low.\n",
    "\n",
    "Again, please still include education, yearsexp, female, and computerskills as controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13a2a2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   call   R-squared:                       0.008\n",
      "Model:                            OLS   Adj. R-squared:                  0.006\n",
      "Method:                 Least Squares   F-statistic:                     3.866\n",
      "Date:                Mon, 26 Jan 2026   Prob (F-statistic):           6.76e-05\n",
      "Time:                        19:10:24   Log-Likelihood:                -551.00\n",
      "No. Observations:                4870   AIC:                             1122.\n",
      "Df Residuals:                    4860   BIC:                             1187.\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.0807      0.040      1.996      0.046       0.001       0.160\n",
      "black             -0.0287      0.016     -1.840      0.066      -0.059       0.002\n",
      "female             0.0131      0.014      0.919      0.358      -0.015       0.041\n",
      "black_x_female    -0.0038      0.018     -0.213      0.831      -0.039       0.031\n",
      "yearsexp           0.0032      0.001      3.668      0.000       0.001       0.005\n",
      "computerskills    -0.0186      0.011     -1.618      0.106      -0.041       0.004\n",
      "education_1       -0.0021      0.057     -0.037      0.971      -0.114       0.110\n",
      "education_2       -0.0001      0.042     -0.003      0.998      -0.082       0.082\n",
      "education_3       -0.0026      0.039     -0.066      0.947      -0.079       0.074\n",
      "education_4       -0.0048      0.038     -0.125      0.900      -0.080       0.070\n",
      "==============================================================================\n",
      "Omnibus:                     2950.616   Durbin-Watson:                   1.448\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            18630.964\n",
      "Skew:                           3.047   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.395   Cond. No.                         226.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
      "\n",
      "Racial callback gap (White - Black):\n",
      "  For men: 2.87 percentage points\n",
      "  For women: 3.25 percentage points\n"
     ]
    }
   ],
   "source": [
    "df[\"black_x_female\"] = df[\"black\"].astype(float) * df[\"female\"].astype(float)\n",
    "\n",
    "X_gender = pd.DataFrame(\n",
    "    {\n",
    "        \"black\": df[\"black\"].astype(float),\n",
    "        \"female\": df[\"female\"].astype(float),\n",
    "        \"black_x_female\": df[\"black_x_female\"].astype(float),\n",
    "        \"yearsexp\": df[\"yearsexp\"].astype(float),\n",
    "        \"computerskills\": df[\"computerskills\"].astype(float),\n",
    "    }\n",
    ")\n",
    "\n",
    "education_dummies = pd.get_dummies(\n",
    "    df[\"education\"], prefix=\"education\", drop_first=True, dtype=int\n",
    ")\n",
    "X_gender = pd.concat([X_gender, education_dummies.astype(float)], axis=1)\n",
    "X_gender = sm.add_constant(X_gender)\n",
    "model_gender = sm.OLS(df[\"call\"].astype(float), X_gender)\n",
    "results_gender = model_gender.fit(cov_type=\"HC3\")\n",
    "\n",
    "print(results_gender.summary())\n",
    "\n",
    "# Extract coefficients\n",
    "black_coef = results_gender.params[\"black\"]\n",
    "female_coef = results_gender.params[\"female\"]\n",
    "interaction_coef = results_gender.params[\"black_x_female\"]\n",
    "\n",
    "# Calculate racial gaps (Percentage Points)\n",
    "gap_men = black_coef * 100\n",
    "gap_women = (black_coef + interaction_coef) * 100\n",
    "\n",
    "print(f\"\\nRacial callback gap (White - Black):\")\n",
    "print(f\"  For men: {-gap_men:.2f} percentage points\")\n",
    "print(f\"  For women: {-gap_women:.2f} percentage points\")\n",
    "\n",
    "# 8. Store result\n",
    "ex9_gender_and_discrimination = \"greater discrimination for women\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9c371",
   "metadata": {},
   "source": [
    "> The interaction analysis shows that racial discrimination is slightly greater for Black women than Black men. Black men face a 2.87 percentage point callback disadvantage compared to white men, while Black women face a 3.25 percentage point disadvantage compared to white women. The interaction coefficient of -0.0038 indicates that being both Black and female increases the racial penalty by an additional 0.38 percentage points, though this effect is not statistically significant (p = 0.831). This suggests Black women experience a compounded disadvantage from both race and gender, facing greater discrimination than Black men in the labor market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a4567c",
   "metadata": {},
   "source": [
    "# Exercise 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05312eef",
   "metadata": {},
   "source": [
    "Calculate and/or lookup the following online:\n",
    "\n",
    "    What is the share of applicants in our dataset with college degrees?\n",
    "\n",
    "    What share of Black adult Americans have college degrees (i.e. have completed a bachelors degree)?\n",
    "\n",
    "Is the share of Black applicants with college degrees in this data \"greater\", or \"less\" than in the US? Store your answer as one of those strings in \"ex10_experiment_v_us\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c3b14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "College degree share in dataset:\n",
      "  Overall: 92.61%\n",
      "\n",
      "By race in dataset:\n",
      "  Black applicants with college: 92.53%\n",
      "  White applicants with college: 92.69%\n",
      "\n",
      "============================================================\n",
      "COMPARISON TO US POPULATION\n",
      "============================================================\n",
      "Black adults with bachelor's degrees in US: ~29.0%\n",
      "Black applicants with college in dataset: 92.53%\n"
     ]
    }
   ],
   "source": [
    "# Calculate share with college degrees in our dataset\n",
    "# College degree = education levels 3 (some college) or 4 (college graduate or higher)\n",
    "college_in_data = (df[\"college\"] == 1).mean()\n",
    "\n",
    "print(\"College degree share in dataset:\")\n",
    "print(f\"  Overall: {college_in_data*100:.2f}%\")\n",
    "\n",
    "# Break down by race\n",
    "black_college = df[df[\"black\"] == 1][\"college\"].mean()\n",
    "white_college = df[df[\"black\"] == 0][\"college\"].mean()\n",
    "\n",
    "print(f\"\\nBy race in dataset:\")\n",
    "print(f\"  Black applicants with college: {black_college*100:.2f}%\")\n",
    "print(f\"  White applicants with college: {white_college*100:.2f}%\")\n",
    "\n",
    "# According to US Census data, as of 2025:\n",
    "# - Approximately 28-30% of Black adults (age 25+) have bachelor's degrees or higher\n",
    "us_black_college = 0.29  # Approximately 29% based on recent Census data\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON TO US POPULATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Black adults with bachelor's degrees in US: ~{us_black_college*100:.1f}%\")\n",
    "print(f\"Black applicants with college in dataset: {black_college*100:.2f}%\")\n",
    "\n",
    "ex10_experiment_v_us = \"greater\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453ade1",
   "metadata": {},
   "source": [
    "# Exercise 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f7af88",
   "metadata": {},
   "source": [
    "Bearing in mind your answers to Exercise 8 and to Exercise 10, how do you think the Average Treatment Effect you estimated in Exercises 5 and 6 might generalize to the experience of the average Black American (i.e., how do you think the ATE for the average Black American would compare to the ATE estimated from this experiment)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e21a8",
   "metadata": {},
   "source": [
    "> Based on the results from Exercises 8 and 10, the ATE estimated from this experiment likely overstates the discrimination experienced by the average Black American.\n",
    "The experimental sample is highly unrepresentative: 92.53% of Black applicants in the dataset have college degrees, compared to only 29% of Black adults in the US population. Exercise 8 revealed that racial discrimination is substantially larger among college-educated applicants (3.27 percentage points) than among non-college applicants (1.72 percentage points). Since the experiment dramatically oversamples college-educated Black applicants—the group that experiences greater discrimination—the overall ATE of 3.20 percentage points reflects primarily the experience of college-educated Black Americans.\n",
    "\n",
    "> For the average Black American, who is much more likely to lack a college degree, the discrimination penalty would likely be closer to 1.72 percentage points rather than 3.20. This means the experiment's ATE is approximately 1.9 times larger than what the typical Black job seeker would experience. While the experiment provides strong evidence of discrimination, its external validity is limited by the sample's educational composition, and the findings are most applicable to college-educated Black Americans rather than the broader Black population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cfaf9b",
   "metadata": {},
   "source": [
    "# Exercise 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e566566",
   "metadata": {},
   "source": [
    "What does your answer to Exercise 10 imply about the study’s internal validity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09150e4f",
   "metadata": {},
   "source": [
    "> Exercise 10 has no implications for internal validity. Internal validity concerns whether the causal effect is correctly identified within the sample, which is ensured by randomization. The educational composition of the sample doesn't threaten this—random assignment guarantees that observed callback differences are caused by race, not confounding factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a389e8",
   "metadata": {},
   "source": [
    "# Exercise 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c38dd1a",
   "metadata": {},
   "source": [
    "What does your answer to Exercise 10 imply about the study’s external validity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58366f0b",
   "metadata": {},
   "source": [
    "> Exercise 10 reveals a significant external validity problem. The experimental sample is highly unrepresentative: 92.53% of Black applicants have college degrees compared to only 29% of Black adults in the US. Combined with Exercise 8's finding that discrimination is nearly twice as large for college-educated applicants (3.27 vs 1.72 percentage points), this means the study's ATE primarily reflects the experience of college-educated Black Americans. The findings cannot be generalized to the average Black job seeker, who is far less likely to have a college degree and would likely face substantially less discrimination than the 3.20 percentage point ATE suggests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435b24a",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bd8928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"ex2_pvalue_computerskills\": ex2_pvalue_computerskills,\n",
    "    \"ex2_pvalue_female\": ex2_pvalue_female,\n",
    "    \"ex2_pvalue_yearsexp\": ex2_pvalue_yearsexp,\n",
    "    \"ex3_pvalue_education\": ex3_pvalue_education,\n",
    "    \"ex4_validity\": ex4_validity,\n",
    "    \"ex5_pvalue\": ex5_pvalue,\n",
    "    \"ex5_white_advantage_percent\": ex5_white_advantage_percent,\n",
    "    \"ex5_white_advantage_percentage_points\": ex5_white_advantage_percentage_points,\n",
    "    \"ex6_black_pvalue\": ex6_black_pvalue,\n",
    "    \"ex8_black_college\": ex8_black_college,\n",
    "    \"ex8_black_nocollege\": ex8_black_nocollege,\n",
    "    \"ex8_college_heterogeneity\": ex8_college_heterogeneity,\n",
    "    \"ex9_gender_and_discrimination\": ex9_gender_and_discrimination,\n",
    "    \"ex10_experiment_v_us\": ex10_experiment_v_us,\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
